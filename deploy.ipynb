{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  155.6kB\n",
      "Step 1/7 : FROM python:3.7.5-slim\n",
      " ---> 9f4008bf3f11\n",
      "Step 2/7 : RUN pip install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 912b14fd13bc\n",
      "Step 3/7 : WORKDIR /app\n",
      " ---> Using cache\n",
      " ---> 0bcfa4bdd446\n",
      "Step 4/7 : COPY ./requirements.txt /app/requirements.txt\n",
      " ---> Using cache\n",
      " ---> d97baa0949fd\n",
      "Step 5/7 : RUN pip install -r requirements.txt\n",
      " ---> Using cache\n",
      " ---> 69718e71bf78\n",
      "Step 6/7 : COPY ./prediction-service.py /app/prediction-service.py\n",
      " ---> b5ee7e99aee3\n",
      "Step 7/7 : ENTRYPOINT [\"python\", \"/app/prediction-service.py\"]\n",
      " ---> Running in 73f0bf16cdd8\n",
      "Removing intermediate container 73f0bf16cdd8\n",
      " ---> 9390615ce15f\n",
      "Successfully built 9390615ce15f\n",
      "Successfully tagged prediction-service:0.1\n"
     ]
    }
   ],
   "source": [
    "!docker build -t prediction-service:0.1 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                        TAG                 IMAGE ID            CREATED             SIZE\n",
      "prediction-service                                0.1                 9390615ce15f        4 seconds ago       550MB\n",
      "<none>                                            <none>              cac8b1ae586d        6 minutes ago       550MB\n",
      "gcr.io/myfirstproject-226013/prediction-service   0.1                 c216cca2a9b4        4 hours ago         554MB\n",
      "gcr.io/myfirstproject-226013/prediction-service   <none>              d2d48f73503c        4 hours ago         554MB\n",
      "gcr.io/myfirstproject-226013/prediction-service   <none>              e59026fd4fb4        5 hours ago         554MB\n",
      "<none>                                            <none>              29ecbf35c211        6 hours ago         554MB\n",
      "<none>                                            <none>              b687175ee781        6 hours ago         499MB\n",
      "<none>                                            <none>              5632baba791d        6 hours ago         497MB\n",
      "<none>                                            <none>              8225e30af2a6        6 hours ago         476MB\n",
      "<none>                                            <none>              ce47c0a5e3d8        6 hours ago         476MB\n",
      "<none>                                            <none>              02bf2cd6d962        9 hours ago         476MB\n",
      "gcr.io/myfirstproject-226013/prediction-service   <none>              2250272d8a7c        10 hours ago        476MB\n",
      "<none>                                            <none>              98474ba93652        10 hours ago        476MB\n",
      "<none>                                            <none>              087c5fa8edf8        10 hours ago        476MB\n",
      "prediction-service                                0.2                 74623286427e        30 hours ago        476MB\n",
      "gcr.io/myfirstproject-226013/prediction-service   0.2                 74623286427e        30 hours ago        476MB\n",
      "<none>                                            <none>              00d4dc13b5c4        30 hours ago        476MB\n",
      "<none>                                            <none>              00a6fae0aecd        30 hours ago        476MB\n",
      "<none>                                            <none>              aa80acd5a88d        30 hours ago        476MB\n",
      "<none>                                            <none>              25efa4d67436        30 hours ago        476MB\n",
      "<none>                                            <none>              7d5df2c0c53d        30 hours ago        476MB\n",
      "<none>                                            <none>              4f307b31e1fe        30 hours ago        476MB\n",
      "<none>                                            <none>              741dd6dcd564        30 hours ago        476MB\n",
      "gcr.io/inverting-proxy/agent                      <none>              f19154b89377        14 months ago       1.07GB\n",
      "python                                            3.7.5-slim          9f4008bf3f11        16 months ago       178MB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8995f8fbe22bdb8a29a170c0c2f384faff793d468b2ab4cf80941d471b99871e\n"
     ]
    }
   ],
   "source": [
    "!docker run -d -p 5000:5000 prediction-service:0.1 --model_dir gs://myfirstproject-226013/titanic/assets_v0/model.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE                          COMMAND                  CREATED             STATUS              PORTS                    NAMES\n",
      "8995f8fbe22b        prediction-service:0.1         \"python /app/predict…\"   3 seconds ago       Up 1 second         0.0.0.0:5000->5000/tcp   jovial_fermi\n",
      "f9587d5d980f        gcr.io/inverting-proxy/agent   \"/bin/sh -c '/opt/bi…\"   2 months ago        Up 2 months                                  proxy-agent\n"
     ]
    }
   ],
   "source": [
    "!docker ps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b905d77eb550\n"
     ]
    }
   ],
   "source": [
    "!docker rm -f b905d77eb550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}"
     ]
    }
   ],
   "source": [
    "! curl http://0.0.0.0:5000/health-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\":[[0.03610385594650279,0.9638961440534972],[0.2665531459715753,0.7334468540284249]]}"
     ]
    }
   ],
   "source": [
    "! curl http://0.0.0.0:5000/predict -d @request.json -H \"Content-Type: application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker tag prediction-service:0.1 gcr.io/myfirstproject-226013/prediction-service:0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a hostname, which specifies location where you will store the image.\n",
    "- gcr.io hosts images in data centers in the United States, but the location may change in the future\n",
    "- us.gcr.io hosts image in data centers in the United States, in a separate storage bucket from images hosted by gcr.io\n",
    "- eu.gcr.io hosts the images in the European Union\n",
    "- asia.gcr.io hosts images in data centers in Asia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [gcr.io/myfirstproject-226013/prediction-service]\n",
      "\n",
      "\u001b[1Bdaf9f7ab: Preparing \n",
      "\u001b[1B792c704d: Preparing \n",
      "\u001b[1B51a58848: Preparing \n",
      "\u001b[1B269e7909: Preparing \n",
      "\u001b[1Beb28bd1d: Preparing \n",
      "\u001b[1B1e895230: Preparing \n",
      "\u001b[1Ba4318145: Preparing \n",
      "\u001b[1Bb6fe98b7: Preparing \n",
      "\u001b[1B9d53a256: Preparing \n",
      "\u001b[9B792c704d: Pushed   366.3MB/358.4MBPushing   2.56kB\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K0.1: digest: sha256:d40f5d575bab9563bfc339e5f3f0f345d2510788e8656b8f581c5d7d290401d6 size: 2416\n"
     ]
    }
   ],
   "source": [
    "! docker push gcr.io/myfirstproject-226013/prediction-service:0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predictions\": [\n",
      "    [\n",
      "      0.99999994756028354,\n",
      "      5.2439716447839138e-08,\n",
      "      3.9605615283401928e-33\n",
      "    ],\n",
      "    [\n",
      "      2.2071453158659351e-08,\n",
      "      0.99993935107495735,\n",
      "      6.0626853589423013e-05\n",
      "    ],\n",
      "    [\n",
      "      3.8355824135947692e-15,\n",
      "      0.022375031945804352,\n",
      "      0.97762496805419186\n",
      "    ]\n",
      "  ],\n",
      "  \"deployedModelId\": \"8147258016517849088\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "! curl -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "https://europe-west4-aiplatform.googleapis.com/v1alpha1/projects/478111835512/locations/europe-west4/endpoints/4870818918861635584:predict \\\n",
    "-d @request.json \\\n",
    "-H \"Content-Type: application/json\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.mnightly-2021-02-02-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:mnightly-2021-02-02-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
