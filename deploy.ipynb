{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  31.74kB\n",
      "Step 1/12 : FROM python:3.7.5-slim\n",
      " ---> 9f4008bf3f11\n",
      "Step 2/12 : RUN pip install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 104212a0d682\n",
      "Step 3/12 : WORKDIR /app\n",
      " ---> Using cache\n",
      " ---> 3eeb5cee7ab6\n",
      "Step 4/12 : COPY ./requirements.txt /app/requirements.txt\n",
      " ---> Using cache\n",
      " ---> 39ea8ad8396a\n",
      "Step 5/12 : RUN pip install -r requirements.txt\n",
      " ---> Using cache\n",
      " ---> 5e22c0f52522\n",
      "Step 6/12 : COPY ./model.joblib /app/model.joblib\n",
      " ---> Using cache\n",
      " ---> 81b4c6da7ca5\n",
      "Step 7/12 : COPY ./prediction-service.py /app/prediction-service.py\n",
      " ---> 69d5b3e686f4\n",
      "Step 8/12 : ENV FLASK_APP=/app/prediction-service.py\n",
      " ---> Running in 68495dda6321\n",
      "Removing intermediate container 68495dda6321\n",
      " ---> 572d3c9c2c2d\n",
      "Step 9/12 : ENV FLASK_RUN_HOST=0.0.0.0\n",
      " ---> Running in ba4c37cba7e5\n",
      "Removing intermediate container ba4c37cba7e5\n",
      " ---> 93a8a4f67be7\n",
      "Step 10/12 : ENV FLASK_RUN_PORT=5000\n",
      " ---> Running in 0f5caa9c185a\n",
      "Removing intermediate container 0f5caa9c185a\n",
      " ---> 8fb1536c93da\n",
      "Step 11/12 : ENV FLASK_DEBUG=1\n",
      " ---> Running in c970b083985d\n",
      "Removing intermediate container c970b083985d\n",
      " ---> b72d310b94ba\n",
      "Step 12/12 : ENTRYPOINT [\"flask\", \"run\"]\n",
      " ---> Running in 092057ee1f7f\n",
      "Removing intermediate container 092057ee1f7f\n",
      " ---> 285d48d92b43\n",
      "Successfully built 285d48d92b43\n",
      "Successfully tagged prediction-service:0.8\n"
     ]
    }
   ],
   "source": [
    "!docker build -t prediction-service:0.8 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                        TAG                 IMAGE ID            CREATED             SIZE\n",
      "prediction-service                                0.8                 285d48d92b43        4 minutes ago       417MB\n",
      "gcr.io/myfirstproject-226013/prediction-service   0.8                 285d48d92b43        4 minutes ago       417MB\n",
      "prediction-service                                0.1                 1f2df8dd0cf6        18 hours ago        417MB\n",
      "prediction-service                                0.2                 1f2df8dd0cf6        18 hours ago        417MB\n",
      "prediction-service                                0.3                 1f2df8dd0cf6        18 hours ago        417MB\n",
      "gcr.io/myfirstproject-226013/prediction-service   0.2                 1f2df8dd0cf6        18 hours ago        417MB\n",
      "gcr.io/myfirstproject-226013/prediction-service   0.3                 1f2df8dd0cf6        18 hours ago        417MB\n",
      "prediction-service                                latest              687b47868c78        18 hours ago        417MB\n",
      "gcr.io/myfirstproject-226013/prediction-service   latest              3bbc66593f77        19 hours ago        417MB\n",
      "<none>                                            <none>              b352dfb6b15f        19 hours ago        417MB\n",
      "<none>                                            <none>              845811a77ede        19 hours ago        417MB\n",
      "<none>                                            <none>              31af9770a9d7        19 hours ago        417MB\n",
      "<none>                                            <none>              e19946ebef60        20 hours ago        417MB\n",
      "<none>                                            <none>              91cc5ccb7a40        20 hours ago        417MB\n",
      "<none>                                            <none>              dd8ca7798765        20 hours ago        417MB\n",
      "<none>                                            <none>              60ca270801fe        20 hours ago        417MB\n",
      "<none>                                            <none>              c93dbb154b25        20 hours ago        417MB\n",
      "<none>                                            <none>              e46bfd2c8dfa        20 hours ago        417MB\n",
      "<none>                                            <none>              e082e212253b        20 hours ago        417MB\n",
      "<none>                                            <none>              ea24fbc54423        20 hours ago        417MB\n",
      "<none>                                            <none>              084ca9362911        22 hours ago        417MB\n",
      "<none>                                            <none>              2988e07e4781        22 hours ago        417MB\n",
      "<none>                                            <none>              afad76173e81        22 hours ago        417MB\n",
      "gcr.io/inverting-proxy/agent                      <none>              f19154b89377        10 months ago       1.07GB\n",
      "python                                            3.7.5-slim          9f4008bf3f11        11 months ago       178MB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309c96ce0bae985b44f1f5298c77e8a58fc14c5132966f67ea07b59679838ec3\n"
     ]
    }
   ],
   "source": [
    "!docker run -d -p 5000:5000 prediction-service:0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE                          COMMAND                  CREATED             STATUS              PORTS                    NAMES\n",
      "309c96ce0bae        prediction-service:0.8         \"flask run\"              21 seconds ago      Up 20 seconds       0.0.0.0:5000->5000/tcp   peaceful_dhawan\n",
      "cfcedd7d9c3a        gcr.io/inverting-proxy/agent   \"/bin/sh -c '/opt/biâ€¦\"   19 hours ago        Up 19 hours                                  proxy-agent\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67e93baa9a69\n"
     ]
    }
   ],
   "source": [
    "!docker rm -f 67e93baa9a69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl http://0.0.0.0:5000/health-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predictions\": [\n",
      "    0, \n",
      "    1, \n",
      "    2\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "! curl http://localhost:5000/predict -d @request.json -H \"Content-Type: application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predictions\": [\n",
      "    [\n",
      "      0.9999999475602835, \n",
      "      5.2439716447839144e-08, \n",
      "      3.9605615283401935e-33\n",
      "    ], \n",
      "    [\n",
      "      2.2071453158659348e-08, \n",
      "      0.9999393510749573, \n",
      "      6.062685358942301e-05\n",
      "    ], \n",
      "    [\n",
      "      3.835582413594769e-15, \n",
      "      0.02237503194580435, \n",
      "      0.9776249680541919\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "! curl http://localhost:5000/predict-proba -d @request.json -H \"Content-Type: application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker tag prediction-service:0.8 gcr.io/myfirstproject-226013/prediction-service:0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a hostname, which specifies location where you will store the image.\n",
    "- gcr.io hosts images in data centers in the United States, but the location may change in the future\n",
    "- us.gcr.io hosts image in data centers in the United States, in a separate storage bucket from images hosted by gcr.io\n",
    "- eu.gcr.io hosts the images in the European Union\n",
    "- asia.gcr.io hosts images in data centers in Asia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [gcr.io/myfirstproject-226013/prediction-service]\n",
      "\n",
      "\u001b[1B04ac471d: Preparing \n",
      "\u001b[1B0b21e5fd: Preparing \n",
      "\u001b[1B1324986f: Preparing \n",
      "\u001b[1B37b4bdee: Preparing \n",
      "\u001b[1B23e6ff78: Preparing \n",
      "\u001b[1B0ef0f877: Preparing \n",
      "\u001b[1B1e895230: Preparing \n",
      "\u001b[1Ba4318145: Preparing \n",
      "\u001b[1Bb6fe98b7: Preparing \n",
      "\u001b[1B9d53a256: Preparing \n",
      "\u001b[11B4ac471d: Pushed lready exists \u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[11A\u001b[2K0.8: digest: sha256:f7827e56586f447098fca674f2f408dce4746864faffee33cdbbc6636dc98b30 size: 2622\n"
     ]
    }
   ],
   "source": [
    "! docker push gcr.io/myfirstproject-226013/prediction-service:0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predictions\": [\n",
      "    0, \n",
      "    1, \n",
      "    2\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "! curl https://probapredict-2rs7rvnylq-uc.a.run.app/predict -d @request.json -H \"Content-Type: application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predictions\": [\n",
      "    [\n",
      "      0.9999999475602835, \n",
      "      5.2439716447839144e-08, \n",
      "      3.9605615283401935e-33\n",
      "    ], \n",
      "    [\n",
      "      2.2071453158659348e-08, \n",
      "      0.9999393510749573, \n",
      "      6.062685358942301e-05\n",
      "    ], \n",
      "    [\n",
      "      3.835582413594769e-15, \n",
      "      0.02237503194580435, \n",
      "      0.9776249680541919\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "! curl https://probapredict-2rs7rvnylq-uc.a.run.app/predict-proba -d @request.json -H \"Content-Type: application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.mnightly-2021-02-02-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:mnightly-2021-02-02-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
